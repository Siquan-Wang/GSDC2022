{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update 7/11/22:**\n",
    "\n",
    "When I originally released this notebook a couple of months ago, the resulting score was 3.135 which was good enough to tie for first place.  Since then the scores have improved significantly and this score is no longer low enough to be competitive.  I have made a couple of updates below to improve the resulting score to 2.67 which as of today is good enough to get you into 27th place out of 461 entries.\n",
    "\n", 
    "The two changes I made were to update the base station locations to account for tetonic plate movement and to replace the rides with hardware clock discontinuities on a point by point basis instead of the entire data set.  I also added a few sort() statements to correct an issue when the code was not run in Windows.\n",
    "\n",
    "--------------------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "**INTRODUCTION**\n",
    "\n",
    "RTKLIB is an open source software library used for (among other things) calculating GNSS solutions from raw observation data.  It was originally written by Tomoji Takasu of the Tokyo University of Marine Science and Technology, but there are now multiple forks available, including the demo5 fork which I maintain. When used to generate PPK (post-processing kinematic) solutions it has two advantages over the baseline solutions provided by Google.  First of all, it uses the carrier phase observations (ADR) as well as the pseduorange observations.  The carrier phase observations are more difficult to use but also have smaller errors than the pseudorange observations.  Secondly, the PPK solutions are differential, relative to a nearby known base location, rather than absolute like the Google solutions.  The differential solution allows us to difference raw observations between the rover and base which effectively cancels most of the satellite orbital, clock, and atmospheric errors, resulting in more accurate solutions.  \n",
    "\n",
    "I describe this process in more detail in [this blog post](https://rtklibexplorer.wordpress.com/2022/01/10/google-smartphone-decimeter-challenge/) in which I share my experience working with last year's GSDC data after the competition was over.  It includes a link to download the code I used to generate RTKLIB solutions for last year's data.  Submitting these solutions to Kaggle (after the competition was over) resulted in a score of 2.15 meters which put it into fifth place on the final Private Leaderboard.\n",
    "\n",
    "I would like to encourage use of RTKLIB in this year's competition and so I am sharing an updated version of the previous code to duplicate my results with this year's data and the most recent RTKLIB code. This code gives a set of solutions that score 3.135 on this year's Public Leaderboad.  The new code is only slightly modified from the previous version, so anyone interested in using RTKLIB for this challenge can start by becoming familiar with the previous code on the previous data.  I would strongly recommend starting with the older code and data because it comes as a complete package and is easier to get results with than what I am presenting here.\n",
    "\n",
    "My hope is to provide a platform which will allow competitors to jump right into extending the existing GNSS theory rather than having to build a solution from scratch. In addition to the C version of RTKLIB I described in the above post, I have recently created an all python subset of RTKLIB for PPK solutions. This runs somewhat slower than the C code but does make an easier development platform. In this notebook I will provide code and guidelines for working with the C code version of RTKLIB.  I will also describe working with the Python version in a separate notebook after I complete this one.\n",
    "\n",
    "In the interestes of getting this out sooner rather than later, this will not be the \"push the button and you get an answer\" kind of notebook.  It will be more like a set of handwritten notes scribbled down quickly while actually running the experiment.  In it's current form you will need to download the pieces of code to your own system, put them together and run locally since it relies on open source compiled code.  In the future I hope to make this more user friendly, but for now it is assumed that you are fairly familiar with python and can debug simple issues that may crop up when trying to follow these instructions.\n",
    "\n",
    "I ran this exercise on a Windows PC but you should be able to run it on linux as well.  In general, the top of each file will have a set of input parameters.  Unless your folder names and paths are identical to mine, you will often need to update these before running.\n",
    "\n",
    "The folder structure I use in this solution is:\n",
    "\n",
    "GSDC_2022\n",
    "\n",
    "    config\n",
    "    \n",
    "    data\n",
    "    \n",
    "      test\n",
    "    \n",
    "      train\n",
    "      \n",
    "    python\n",
    "   \n",
    "      android_rinex\n",
    "      \n",
    "      rtklib-py\n",
    "      \n",
    "    rtklib\n",
    "\n",
    "It will be easier to follow these instuctions if you use the same folder structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Retrieve base observation and satellite navigation files**\n",
    "\n",
    "Since these are differential solutions, we will need raw observation measurements from a nearby base station for each data set.  Fortunately, these are available from the National Geodetic Survey (NGS) website.  We will also need satellite orbital data for each data set for the GPS, GLONASS, and Galileo constellations.  These are available from multiple websites.  I chose to retrieve them from the UNAVCO site, in part because these files include Galileo navigation data as well as GPS and GLONASS.  Some of the other sources include only GPS and GLONASS.\n",
    "\n",
    "Last year it was sufficient to use a single base station for every data set since they were all located in a small geographic area.  This year there are data sets from the Bay Area and from the LA area, so we will need to select the appropriate base station for each data set and also use the correct location for that base station in the solution.\n",
    "\n",
    "The code below simply retrieves the base and navigation data for the full day corresponding to the starting time of each data set.  This works fine for the test data set since all data sets start and end on the same UTC day but but in the training set there are multiple data sets that start in one (UTC) day and finish in the next day.  I will be demonstrating this exercise on the test data so will not worry about this issue but if you are trying to retrieve this data for the training data you will either need to eliminate the multi-day sets or manually download a file with the correct starting and stopping times.  This is most easily done from the \"User Friendly CORS\" page on the NGS site.\n",
    "\n",
    "The observation files are doubly compressed.  They first need to be decompressed with gzip and then with crx2rnx.  This second step translates from compressed rinex to uncompressed and requires an executable file from RTKLIB.\n",
    "\n",
    "You can download the RTKLIB executables for Windows at https://github.com/rtklibexplorer/RTKLIB/releases.  Put them in the GSDC_2022/rtklib folder.  Note that these are for the demo5 fork of RTKLIB which I maintain.  You can use any fork of RTKLIB for this step, but later when we are calulating the solutions, you will need to use the demo5 fork.  If you are running in Linux, you will need to build your own executables from the source code.  This is decribed at https://rtklibexplorer.wordpress.com/2020/12/18/building-rtklib-code-in-linux/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymap3d\n",
      "  Downloading pymap3d-2.9.1-py3-none-any.whl (53 kB)\n",
      "Installing collected packages: pymap3d\n",
      "Successfully installed pymap3d-2.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymap3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile D:\\kaggle\\GSDC2022\\config\\bases.sta\n",
    "%  LATITUDE(DEG) LONGITUDE(DEG)    HEIGHT(M)   NAME\n",
    "37.41652004  -122.20426728  63.678  SLAC\n",
    "34.17856759  -118.22000401  318.030  VDCY\n",
    "37.53924280  -122.08326960  53.400  P222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile D:\\kaggle\\GSDC2022\\config\\ppk_phone_0510.conf\n",
    "# ppk_phone_0510.conf - config file for RTKLIB PPK solution\n",
    "#2.9549\n",
    "pos1-posmode       =kinematic  #\n",
    "pos1-frequency     =l1+l2+l5   #\n",
    "pos1-soltype       =combined-nophasereset #\n",
    "pos1-elmask        =15         #\n",
    "pos1-snrmask_r     =on         #\n",
    "pos1-snrmask_b     =on         #\n",
    "pos1-snrmask_L1    =24,28,28,32,28,28,24,24,24\n",
    "pos1-snrmask_L2    =34,34,34,34,34,34,34,34,34\n",
    "pos1-snrmask_L5    =24,20,20,24,20,28,28,20,20 #pos1-snrmask_L5    =24,20,24,24,24,28,28,20,20\n",
    "pos1-dynamics      =on         #\n",
    "pos1-tidecorr      =on        #\n",
    "pos1-ionoopt       =brdc       #\n",
    "pos1-tropopt       =saas       #\n",
    "pos1-sateph        =brdc       #\n",
    "pos1-posopt1       =off        #\n",
    "pos1-posopt2       =off        #\n",
    "pos1-posopt3       =off        # \n",
    "pos1-posopt4       =off        # \n",
    "pos1-posopt5       =off        #\n",
    "pos1-posopt6       =off        #\n",
    "pos1-exclsats      =           # \n",
    "pos1-navsys        =13         # \n",
    "pos2-armode        =off        # \n",
    "pos2-gloarmode     =off        # \n",
    "pos2-bdsarmode     =on         # \n",
    "pos2-arfilter      =on         #\n",
    "pos2-arthres       =3\n",
    "pos2-arthresmin    =1.5\n",
    "pos2-arthresmax    =10\n",
    "\n",
    "pos2-arthres1      =0.25\n",
    "pos2-arthres2      =0\n",
    "pos2-arthres3      =1e-09\n",
    "pos2-arthres4      =1e-05\n",
    "pos2-varholdamb    =0.7        # (cyc^2)\n",
    "pos2-gainholdamb   =0.01\n",
    "\n",
    "pos2-arlockcnt     =0\n",
    "pos2-minfixsats    =4\n",
    "pos2-minholdsats   =5\n",
    "pos2-mindropsats   =10\n",
    "pos2-arelmask      =0         # (deg)\n",
    "pos2-arminfix      =50\n",
    "pos2-armaxiter     =1\n",
    "pos2-elmaskhold    =15         # (deg)\n",
    "pos2-aroutcnt      =4\n",
    "pos2-maxage        =30         # (s)\n",
    "pos2-syncsol       =off        #\n",
    "pos2-slipthres     =0.1        #\n",
    "pos2-dopthres      =5          #\n",
    "pos2-rejionno      =1          # (m)\n",
    "pos2-rejgdop       =30\n",
    "pos2-niter         =1\n",
    "pos2-baselen       =0          # (m)\n",
    "pos2-basesig       =0          # (m)\n",
    "out-solformat      =llh        # \n",
    "out-outhead        =on         #\n",
    "out-outopt         =on         # \n",
    "out-outvel         =off        # \n",
    "out-timesys        =gpst       # \n",
    "out-timeform       =tow        # \n",
    "out-timendec       =3\n",
    "out-degform        =deg        # \n",
    "out-fieldsep       =\n",
    "out-outsingle      =off        # \n",
    "out-maxsolstd      =0          # (m)\n",
    "out-height         =ellipsoidal # \n",
    "out-geoid          =internal   # \n",
    "out-solstatic      =all        # \n",
    "out-nmeaintv1      =0          # (s)\n",
    "out-nmeaintv2      =0          # (s)\n",
    "out-outstat        =residual   # \n",
    "stats-eratio1      =400        #\n",
    "stats-eratio2      =300\n",
    "stats-eratio5      =100\n",
    "stats-errphase     =0.006      # (m) \n",
    "stats-errphaseel   =0.003      # (m)\n",
    "stats-errphasebl   =0          # (m/10km)\n",
    "stats-errdoppler   =1          # (Hz)\n",
    "stats-snrmax       =50         # (dB.Hz)\n",
    "stats-errsnr       =0          # (m)\n",
    "stats-errrcv       =0          # ( )\n",
    "stats-stdbias      =30         # (m)\n",
    "stats-stdiono      =0.03       # (m)\n",
    "stats-stdtrop      =0.3        # (m)\n",
    "\n",
    "stats-prnaccelh    =1          # (m/s^2)\n",
    "stats-prnaccelv    =0.1          # (m/s^2)\n",
    "\n",
    "stats-prnbias      =0.032       # \n",
    "\n",
    "stats-prniono      =0.001      # (m)\n",
    "stats-prntrop      =0.0001     # (m)\n",
    "stats-prnpos       =0          # (m)\n",
    "stats-clkstab      =5e-12      # (s/s)\n",
    "ant1-postype       =llh        # \n",
    "ant1-pos1          =0          # \n",
    "ant1-pos2          =0          \n",
    "ant1-pos3          =0          \n",
    "ant1-anttype       =\n",
    "ant1-antdele       =0          \n",
    "ant1-antdeln       =0          \n",
    "ant1-antdelu       =0          \n",
    "ant2-postype       =posfile    \n",
    "ant2-pos1          =0          \n",
    "ant2-pos2          =0          \n",
    "ant2-pos3          =0          \n",
    "ant2-anttype       =\n",
    "ant2-antdele       =0          \n",
    "ant2-antdeln       =0          \n",
    "ant2-antdelu       =0          \n",
    "ant2-maxaveep      =1\n",
    "ant2-initrst       =off         \n",
    "misc-timeinterp    =off         \n",
    "misc-sbasatsel     =0          \n",
    "misc-rnxopt1       =\n",
    "misc-rnxopt2       =\n",
    "misc-pppopt        =\n",
    "misc-svrcycle      =5         # (ms)\n",
    "misc-timeout       =10000      # (ms)\n",
    "misc-reconnect     =10000      # (ms)\n",
    "misc-nmeacycle     =5000       # (ms)\n",
    "misc-buffsize      =32768      # (bytes)\n",
    "misc-navmsgsel     =all        # (0:all,1:rover,2:base,3:corr)\n",
    "misc-proxyaddr     =\n",
    "misc-fswapmargin   =30         # (s)\n",
    "file-satantfile    =\n",
    "file-rcvantfile    =\n",
    "file-staposfile    =D:\\kaggle\\GSDC2022\\config\\bases.sta\n",
    "file-geoidfile     =\n",
    "file-ionofile      =\n",
    "file-dcbfile       =\n",
    "file-eopfile       =\n",
    "file-blqfile       =\n",
    "file-tempdir       =\n",
    "file-geexefile     =\n",
    "file-solstatfile   =\n",
    "file-tracefile     ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "get_base_data.py - retrieve base observation and navigation data for the\n",
    "    2022 GSDC competition \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests\n",
    "import gzip\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# Input parameters\n",
    "#D:\\kaggle\\GSDC2022\\smartphone-decimeter-2022\\test\n",
    "datadir = r'D:\\kaggle\\GSDC2022\\smartphone-decimeter-2022\\train'\n",
    "stas = ['slac', 'vdcy', 'p222']  # Bay Area, LA. backup for Bay Area\n",
    "obs_url_base = 'https://geodesy.noaa.gov/corsdata/rinex'\n",
    "nav_url_base = 'https://data.unavco.org/archive/gnss/rinex3/nav' \n",
    "nav_file_base = 'AC0300USA_R_'  # 20210060000_01D_MN.rnx.gz\n",
    "\n",
    "# Make sure you have downloaded this executable before running this code\n",
    "crx2rnx_bin = r'D:\\kaggle\\GSDC2022\\rtklib\\crx2rnx.exe'\n",
    "\n",
    "\n",
    "os.chdir(datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-15-US-MTV-1\n",
      "2020-05-21-US-MTV-1\n",
      "2020-05-21-US-MTV-2\n",
      "2020-05-28-US-MTV-2\n",
      "2020-05-29-US-MTV-1\n",
      "2020-05-29-US-MTV-2\n",
      "2020-06-04-US-MTV-1\n",
      "2020-06-04-US-MTV-2\n",
      "2020-06-05-US-MTV-1\n",
      "2020-06-05-US-MTV-2\n",
      "2020-06-10-US-MTV-1\n",
      "2020-06-10-US-MTV-2\n",
      "2020-06-11-US-MTV-1\n",
      "2020-06-18-US-MTV-1\n",
      "2020-06-24-US-MTV-1\n",
      "2020-06-24-US-MTV-2\n",
      "2020-07-08-US-MTV-1\n",
      "2020-07-08-US-MTV-2\n",
      "2020-07-17-US-MTV-2\n",
      "2020-07-24-US-MTV-1\n",
      "2020-07-24-US-MTV-2\n",
      "2020-08-03-US-MTV-1\n",
      "2020-08-03-US-MTV-2\n",
      "2020-08-06-US-MTV-1\n",
      "2020-08-06-US-MTV-2\n",
      "2020-08-11-US-MTV-1\n",
      "2020-08-11-US-MTV-2\n",
      "2020-08-13-US-MTV-1\n",
      "2020-09-04-US-MTV-1\n",
      "2020-09-04-US-MTV-2\n",
      "2020-11-23-US-MTV-1\n",
      "2020-12-10-US-SJC-1\n",
      "2020-12-10-US-SJC-2\n",
      "2021-01-04-US-SFO-1\n",
      "2021-01-04-US-SFO-2\n",
      "2021-01-05-US-MTV-1\n",
      "2021-01-05-US-MTV-2\n",
      "2021-03-10-US-MTV-1\n",
      "2021-03-16-US-MTV-1\n",
      "2021-03-16-US-MTV-2\n",
      "2021-03-16-US-MTV-3\n",
      "2021-04-02-US-SJC-1\n",
      "2021-04-08-US-MTV-1\n",
      "2021-04-21-US-MTV-2\n",
      "2021-04-26-US-SVL-2\n",
      "2021-04-28-US-MTV-1\n",
      "2021-04-29-US-MTV-1\n",
      "2021-04-29-US-MTV-2\n",
      "2021-07-01-US-MTV-1\n",
      "2021-07-14-US-MTV-1\n",
      "2021-07-19-US-MTV-1\n",
      "2021-07-27-US-MTV-1\n",
      "2021-08-04-US-SJC-1\n",
      "2021-08-24-US-SVL-1\n",
      "2021-12-07-US-LAX-1\n",
      "2021-12-07-US-LAX-2\n",
      "2021-12-08-US-LAX-1\n",
      "2021-12-08-US-LAX-3\n",
      "2021-12-08-US-LAX-5\n",
      "2021-12-09-US-LAX-2\n",
      "2021-12-15-US-MTV-1\n",
      "2021-12-28-US-MTV-1\n"
     ]
    }
   ],
   "source": [
    "for dataset in np.sort(os.listdir()):\n",
    "    if not os.path.isdir(dataset):\n",
    "        continue\n",
    "    print(dataset)\n",
    "    ymd = dataset.split('-')\n",
    "    doy = datetime(int(ymd[0]), int(ymd[1]), int(ymd[2])).timetuple().tm_yday # get day of year\n",
    "    doy = str(doy).zfill(3)\n",
    "    \n",
    "    if len(glob(os.path.join(dataset,'*.*o'))) == 0:\n",
    "        # get obs data\n",
    "        i = 1 if '-LAX-' in dataset else 0  # use different base for LA\n",
    "        fname = stas[i] + doy + '0.' + ymd[0][2:4] + 'd.gz'\n",
    "        url = '/'.join([obs_url_base, ymd[0], doy, stas[i], fname])\n",
    "        try:\n",
    "            obs = gzip.decompress(requests.get(url).content) # get obs and decompress\n",
    "            # write obs data\n",
    "            open(os.path.join(dataset, fname[:-3]), \"wb\").write(obs)\n",
    "        except:\n",
    "            # try backup CORS station\n",
    "            i += 2\n",
    "            fname = stas[i] + doy + '0.' + ymd[0][2:4] + 'd.gz'\n",
    "            url = '/'.join([obs_url_base, ymd[0], doy, stas[i], fname])\n",
    "            try:\n",
    "                obs = gzip.decompress(requests.get(url).content) # get obs and decompress\n",
    "                # write obs data\n",
    "                open(os.path.join(dataset, fname[:-3]), \"wb\").write(obs)\n",
    "            except:\n",
    "                print('Fail obs: %s' % dataset)\n",
    "            \n",
    "        # convert crx to rnx\n",
    "        crx_files = glob(os.path.join(dataset,'*.*d'))\n",
    "        if len(crx_files) > 0:\n",
    "            os.system(crx2rnx_bin + ' ' + crx_files[0])\n",
    "    \n",
    "    # get nav data\n",
    "    if len(glob(os.path.join(dataset,'*.rnx'))) > 0:\n",
    "           continue  # file already exists\n",
    "    fname = nav_file_base + ymd[0] + doy + '0000_01D_MN' + '.rnx.gz'\n",
    "    url = '/'.join([nav_url_base, ymd[0], doy, fname])\n",
    "    try:\n",
    "        obs = gzip.decompress(requests.get(url).content) # get obs and decompress    \n",
    "        # write nav data\n",
    "        open(os.path.join(dataset, fname[:-3]), \"wb\").write(obs)\n",
    "    except:\n",
    "        print('Fail nav: %s' % dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Download and update android_rinex library and create RTKLIB config file**\n",
    "\n",
    "You will need the android_rinex library for converting the raw Android observation files to rinex format.  RTKLIB post processing solutions require that the input files be in the rinex format.  You will need to use my fork of this library which is available at the address shown in the code below. Make sure you have the most recent version which was updated on 7/13/22\n",
    "\n",
    "\n",
    "Put this in the GSDC_2022/python/android_rinex folder.  (Temporary workaround: There is currently a path issue when running in multi-processing mode.  For now, you will need to copy the files from the android_rinex/src folder into the GSDC_2022/python folder)\n",
    "\n",
    "\n",
    "\n",
    "You will also need a configuration file for the solution. Copy the config file below to the GSDC_2022/config folder with a file name of ppk_phone_0510.conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "\n",
    "#git clone https://github.com/rtklibexplorer/android_rinex.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run_ppk_multi.py - convert raw android files to rinex and run PPK solutions for GDSC_2022\n",
    "data set with RTKLIB and/or rtklib-py.   \n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "#if 'rtklib-py/src' not in sys.path:\n",
    "sys.path.append(r'D:\\kaggle\\GSDC2022\\python\\rtklib-py')\n",
    "#if 'android_rinex/src' not in sys.path:\n",
    "sys.path.append(r'D:\\kaggle\\GSDC2022\\python\\android_rinex\\src')\n",
    "\n",
    "import os, shutil\n",
    "from os.path import join, isdir, isfile\n",
    "from glob import glob\n",
    "from multiprocessing import Pool\n",
    "import subprocess\n",
    "import gnsslogger_to_rnx as rnx\n",
    "from time import time\n",
    "\n",
    "# set run parameters\n",
    "maxepoch = None # max number of epochs, used for debug, None = no limit\n",
    "\n",
    "# Set solution choices\n",
    "ENABLE_PY = False        # Use RTKLIB-PY to generate solutions \n",
    "ENABLE_RTKLIB = True     # Use RTKLIB to generate solutions\n",
    "OVERWRITE_RINEX = True  # overwrite existing rinex filex\n",
    "OVERWRITE_SOL = True    # overwrite existing solution files\n",
    "\n",
    "# specify location of input folder and files\n",
    "datadir = r'D:\\kaggle\\GSDC2022\\smartphone-decimeter-2022\\train'\n",
    "basefiles = '../*0.2*o' # rinex2, use this for rtklib only\n",
    "#basefiles = '../base.obs' # rinex3, use this for python only\n",
    "navfiles = '../*MN.rnx' # navigation files with wild cards\n",
    "\n",
    "# Setup for RTKLIB \n",
    "binpath_rtklib  = r'D:\\kaggle\\GSDC2022\\rtklib\\rnx2rtkp.exe'\n",
    "cfgfile_rtklib = r'D:\\kaggle\\GSDC2022\\config\\ppk_phone_0510.conf'\n",
    "soltag_rtklib = '_rtklib' # postfix for solution file names\n",
    "\n",
    "# Setup for rtklib-py\n",
    "cfgfile = r'D:\\kaggle\\GSDC2022\\config\\ppk_phone_0510.py' # cfgfile must be absolute path\n",
    "soltag_py = '_py0510'  # postfix for solution file names\n",
    "\n",
    "PHONES = ['GooglePixel4', 'GooglePixel4XL', 'Pixel4Modded', 'GooglePixel5', 'GooglePixel6Pro', 'XiaomiMi8', 'SamsungGalaxyS20Ultra']\n",
    "BASE_POS = {'slac' : [-2703115.9184, -4291767.2037, 3854247.9027],  # WGS84 XYZ coordinates\n",
    "            'vdcy' : [-2497836.5139, -4654543.2609, 3563028.9379],\n",
    "            'p222' : [-2689640.2891, -4290437.3671, 3865050.9313]}\n",
    "\n",
    "\n",
    "# input structure for rinex conversion\n",
    "class args:\n",
    "    def __init__(self):\n",
    "        # Input parameters for conversion to rinex\n",
    "        self.slip_mask = 0 # overwritten below\n",
    "        self.fix_bias = True\n",
    "        self.timeadj = 1e-7\n",
    "        self.pseudorange_bias = 0\n",
    "        self.filter_mode = 'sync'\n",
    "        # Optional hader values for rinex files\n",
    "        self.marker_name = ''\n",
    "        self.observer = ''\n",
    "        self.agency = ''\n",
    "        self.receiver_number = ''\n",
    "        self.receiver_type = ''\n",
    "        self.receiver_version = ''\n",
    "        self.antenna_number = ''\n",
    "        self.antenna_type = ''\n",
    "\n",
    "# Copy and read config file\n",
    "if ENABLE_PY:\n",
    "    shutil.copyfile(cfgfile, '__ppk_config.py')\n",
    "    import __ppk_config as cfg\n",
    "    import rinex as rn\n",
    "    import rtkcmn as gn\n",
    "    from rtkpos import rtkinit\n",
    "    from postpos import procpos, savesol\n",
    "\n",
    "# function to convert single rinex file\n",
    "def convert_rnx(folder, rawFile, rovFile, slipMask):\n",
    "    os.chdir(folder)\n",
    "    argsIn = args()\n",
    "    argsIn.input_log = rawFile\n",
    "    argsIn.output = os.path.basename(rovFile)\n",
    "    argsIn.slip_mask = slipMask\n",
    "    rnx.convert2rnx(argsIn)\n",
    "\n",
    "# function to run single RTKLIB-Py solution\n",
    "def run_ppk(folder, rovfile, basefile, navfile, solfile):\n",
    "    # init solution\n",
    "    os.chdir(folder)\n",
    "    gn.tracelevel(0)\n",
    "    nav = rtkinit(cfg)\n",
    "    nav.maxepoch = maxepoch\n",
    "    print(folder)\n",
    "\n",
    "    # load rover obs\n",
    "    rov = rn.rnx_decode(cfg)\n",
    "    print('    Reading rover obs...')\n",
    "    if nav.filtertype == 'backward':\n",
    "        maxobs = None   # load all obs for backwards\n",
    "    else:\n",
    "        maxobs = maxepoch\n",
    "    rov.decode_obsfile(nav, rovfile, maxobs)\n",
    "\n",
    "    # load base obs and location\n",
    "    base = rn.rnx_decode(cfg)\n",
    "    print('   Reading base obs...')\n",
    "    base.decode_obsfile(nav, basefile, None)\n",
    "    \n",
    "    # determine base location from original base obs file name\n",
    "    if len(BASE_POS) > 1:\n",
    "        baseName = glob('../*.2*o')[0][-12:-8]\n",
    "        nav.rb[0:3]  = BASE_POS[baseName]\n",
    "    elif nav.rb[0] == 0:\n",
    "        nav.rb = base.pos # from obs file\n",
    "        \n",
    "    # load nav data from rover obs\n",
    "    print('   Reading nav data...')\n",
    "    rov.decode_nav(navfile, nav)\n",
    "\n",
    "    # calculate solution\n",
    "    print('    Calculating solution...')\n",
    "    sol = procpos(nav, rov, base)\n",
    "\n",
    "    # save solution to file\n",
    "    savesol(sol, solfile)\n",
    "    return rovfile\n",
    "\n",
    "# function to run single RTKLIB solution\n",
    "def run_rtklib(folder, rovfile, basefile, navfile, solfile):\n",
    "    # create command to run solution\n",
    "    rtkcmd='%s -x 0 -y 2 -k %s -o %s %s %s %s' % \\\n",
    "        (binpath_rtklib, cfgfile_rtklib, solfile, rovfile, basefile, navfile)\n",
    "    \n",
    "    # run command\n",
    "    os.chdir(folder)\n",
    "    subprocess.run(rtkcmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)   \n",
    "\n",
    "####### Start of main code ##########################\n",
    "\n",
    "def main():\n",
    "\n",
    "    # get list of data sets in data path\n",
    "    datasets = np.sort(os.listdir(datadir))\n",
    "\n",
    "    # loop through data set folders\n",
    "    rinexIn = []\n",
    "    ppkIn = []\n",
    "    rtklibIn = []\n",
    "    for dataset in datasets:\n",
    "        if dataset in ['2020-08-06-US-MTV-1',\n",
    "                '2020-08-06-US-MTV-2',\n",
    "                '2020-11-23-US-MTV-1',\n",
    "                '2021-03-16-US-MTV-2',\n",
    "                '2021-04-21-US-MTV-2',\n",
    "                '2021-04-29-US-MTV-1',\n",
    "                '2021-04-29-US-MTV-2',\n",
    "                '2021-12-15-US-MTV-1',\n",
    "                '2021-12-28-US-MTV-1'\n",
    "                ]:\n",
    "            continue\n",
    "        for phone in PHONES:\n",
    "            # skip if no folder for this phone\n",
    "            folder = join(datadir, dataset, phone)\n",
    "            if not isdir(folder):  \n",
    "                continue\n",
    "            os.chdir(folder)\n",
    "            rawFile = join('supplemental', 'gnss_log.txt')\n",
    "            rovFile = join('supplemental', 'gnss_log.obs')\n",
    "\n",
    "            rinex = False\n",
    "            # check if need rinex conversion\n",
    "            if OVERWRITE_RINEX or not isfile(rovFile):\n",
    "                # generate list of input parameters for each rinex conversion\n",
    "                if phone == 'SamsungS20Ultra': # Use cycle slip flags for Samsung phones\n",
    "                    slipMask = 0 # 1 to unmask recevier cycle slips\n",
    "                else:\n",
    "                    slipMask = 0 \n",
    "                rinexIn.append((folder, rawFile, rovFile, slipMask))\n",
    "                print(rawFile, '->', rovFile) \n",
    "                rinex = True\n",
    "            \n",
    "            # check if need to create PPK solution\n",
    "            try:\n",
    "                baseFile = glob(basefiles)[0]\n",
    "                navFile = glob(navfiles)[0]\n",
    "                solFile = rovFile[:-4] + soltag_py + '.pos'\n",
    "                solFile_rtklib = rovFile[:-4] + soltag_rtklib + '.pos'\n",
    "            except:\n",
    "                print(folder,'  Error: Missing file')\n",
    "                continue\n",
    "            if ENABLE_PY and (OVERWRITE_SOL == True or len(glob(solFile)) == 0 \n",
    "                              or rinex == True):\n",
    "                # generate list of input/output files for each python ppk solution\n",
    "                print('PY: ', join(dataset, phone))\n",
    "                ppkIn.append((folder, rovFile, baseFile, navFile, solFile))\n",
    "            if ENABLE_RTKLIB and (OVERWRITE_SOL == True or \n",
    "                        len(glob(solFile_rtklib)) == 0 or rinex == True):\n",
    "                # generate list of input/output files for each rtklib ppk solution\n",
    "                print('RTKLIB: ', join(dataset, phone))\n",
    "                rtklibIn.append((folder, rovFile, baseFile, navFile, solFile_rtklib))\n",
    "\n",
    "    if len(rinexIn) > 0:\n",
    "        print('\\nConvert rinex files...')\n",
    "        # generate rinx obs files in parallel, does not give error messages\n",
    "        #with Pool() as pool: # defaults to using cpu_count for number of procceses\n",
    "        #    res = pool.starmap(convert_rnx, rinexIn)\n",
    "        # run sequentially, use for debug\n",
    "        for input in rinexIn:\n",
    "            convert_rnx(input[0],input[1],input[2],input[3])\n",
    "\n",
    "    if ENABLE_PY and len(ppkIn) > 0:\n",
    "        print('Calculate PPK solutions...')\n",
    "        # run PPK solutions in parallel, does not give error messages\n",
    "        # with Pool() as pool: # defaults to using cpu_count for number of procceses\n",
    "        #     res = pool.starmap(run_ppk, ppkIn)\n",
    "        # run sequentially, use for debug\n",
    "        for input in ppkIn:\n",
    "            run_ppk(input[0],input[1],input[2],input[3],input[4])\n",
    "\n",
    "    if ENABLE_RTKLIB and len(rtklibIn) > 0:\n",
    "        print('Calculate RTKLIB solutions...')\n",
    "        # run PPK solutions in parallel, does not give error messages\n",
    "        # with Pool() as pool: # defaults to using cpu_count for number of procceses\n",
    "        #     res = pool.starmap(run_rtklib, rtklibIn)\n",
    "        # run sequentially, use for debug\n",
    "        for input in rtklibIn:\n",
    "            run_rtklib(input[0],input[1],input[2],input[3],input[4])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t0 = time()\n",
    "    main()\n",
    "    print('Runtime=%.1f' % (time() - t0))\n",
    "\n",
    "\"\"\" create_baseline_csv_from_pos.py -  Create csv file PPK solution files using timestamps in reference file\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from os.path import join, isfile\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "########### Input parameters ###############################\n",
    "\n",
    "DATA_SET = 'train'\n",
    "SOL_TAG = '_rtklib'\n",
    "datapath = r'D:\\kaggle\\GSDC2022\\smartphone-decimeter-2022'\n",
    "hdrlen = 25    # 25 for RTKLIB, 1 for rtklib-py\n",
    "\n",
    "# Also make sure the appropriate reference file is in the datapath\n",
    "#  test: sample_submission.csv - provided in Google data\n",
    "# train: ground_truths_train.csv - created with crete_ground_truths.py\n",
    "\n",
    "############################################################\n",
    "\n",
    "GPS_TO_UTC = 315964782  # second\n",
    "\n",
    "\n",
    "# get timestamps from existing baseline file\n",
    "os.chdir(datapath)\n",
    "if DATA_SET == 'train':\n",
    "    baseline_file = 'ground_truths_train.csv'\n",
    "else: # 'test'\n",
    "    baseline_file = 'sample_submission.csv'\n",
    "base_txt = np.genfromtxt(baseline_file, delimiter=',',invalid_raise=False, \n",
    "                         skip_header=1, dtype=str)\n",
    "msecs_base = base_txt[:,1].astype(np.int64)\n",
    "phones_base = base_txt[:,0]\n",
    "\n",
    "# open output file\n",
    "fout =open('baseline_locations_' + DATA_SET + '_' + 'CV' + '.csv','w')\n",
    "fout.write('tripId,UnixTimeMillis,LatitudeDegrees,LongitudeDegrees\\n')\n",
    "\n",
    "# get list of data sets in data path\n",
    "os.chdir(join(datapath, DATA_SET))\n",
    "trips = np.sort(os.listdir())\n",
    "\n",
    "# loop through data set folders\n",
    "ix_b = 0\n",
    "for trip in trips:\n",
    "    if isfile(trip) or trip in ['2020-08-06-US-MTV-1',\n",
    "                                '2020-08-06-US-MTV-2',\n",
    "                                '2020-11-23-US-MTV-1',\n",
    "                                '2021-03-16-US-MTV-2',\n",
    "                                '2021-04-21-US-MTV-2',\n",
    "                                '2021-04-29-US-MTV-1',\n",
    "                                '2021-04-29-US-MTV-2',\n",
    "                                '2021-12-15-US-MTV-1',\n",
    "                                '2021-12-28-US-MTV-1'\n",
    "                                ]:\n",
    "        continue\n",
    "    phones = os.listdir(trip)\n",
    "    # loop through phone folders\n",
    "    for phone in phones:\n",
    "        # check for valid folder and file\n",
    "        folder = join(trip, phone)\n",
    "        if isfile(folder):\n",
    "            continue\n",
    "        trip_phone = trip + '/' + phone\n",
    "        #if trip_phone in ['2020-06-24-US-MTV-1/GooglePixel4', \n",
    "        #                  '2020-06-24-US-MTV-1/GooglePixel4XL',\n",
    "        #                 '2020-06-24-US-MTV-2/GooglePixel4',\n",
    "        #                 '2020-06-24-US-MTV-2/GooglePixel4XL',\n",
    "        #                 '2020-08-03-US-MTV-2/GooglePixel4',\n",
    "        #                 '2020-08-03-US-MTV-2/GooglePixel4XL',\n",
    "        #                 '2020-08-03-US-MTV-2/GooglePixel5',\n",
    "        #                 '2020-11-23-US-MTV-1/XiaomiMi8',\n",
    "        #                 '2020-06-04-US-MTV-2/GooglePixel4']:\n",
    "        #    continue\n",
    "        print(trip_phone)\n",
    "\n",
    "        ix_b = np.where(phones_base == trip_phone)[0]\n",
    "        sol_path = join(folder, 'supplemental', 'gnss_log' + SOL_TAG + '.pos')\n",
    "        if isfile(sol_path):\n",
    "            # parse solution file\n",
    "            fields = np.genfromtxt(sol_path, invalid_raise=False, skip_header=hdrlen)\n",
    "            #print(fields)\n",
    "            try:\n",
    "                if int(fields[0,1]) > int(fields[-1,1]): # invert if backwards solution\n",
    "                    fields = fields[::-1]\n",
    "                pos = fields[:,2:5]\n",
    "                qs = fields[:,5].astype(int)\n",
    "                nss = fields[:,6].astype(int)\n",
    "                acc = fields[:,7:13]\n",
    "                msecs = (1000 * (fields[:,0] * 7 * 24 * 3600 + fields[:,1])).astype(np.int64)\n",
    "                msecs += GPS_TO_UTC * 1000\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            print('File not found: ', sol_path)\n",
    "            msecs = msecs_base.copy()\n",
    "            pos = acc = np.zeros((len(msecs), 3))\n",
    "            qs = nss = np.zeros(len(msecs))\n",
    "            \n",
    "           \n",
    "        # interpolate to baseline timestamps to fill in missing samples\n",
    "        llhs = []; stds = []\n",
    "        for j in range(6):\n",
    "            if j < 3:\n",
    "                llhs.append(np.interp(msecs_base[ix_b], msecs, pos[:,j]))\n",
    "                stds.append(np.interp(msecs_base[ix_b], msecs, acc[:,j],\n",
    "                                     left=1000, right=1000))\n",
    "            qsi = np.interp(msecs_base[ix_b], msecs, qs)\n",
    "            nssi = np.interp(msecs_base[ix_b], msecs, nss)\n",
    "            \n",
    "            \n",
    "\n",
    "        # write results to combined file\n",
    "        for i in range(len(ix_b)):\n",
    "                fout.write('%s,%d,%.12f,%.12f,%.2f,%.0f,%.0f,%.3f,%.3f,%.3f\\n' % \n",
    "                        (trip_phone, msecs_base[ix_b[i]], llhs[0][i], llhs[1][i],\n",
    "                         llhs[2][i], qsi[i], nssi[i], stds[0][i], stds[1][i], \n",
    "                         stds[2][i]))\n",
    "fout.close()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymap3d as pm\n",
    "import pymap3d.vincenty as pmv\n",
    "\n",
    "# Compute distance by Vincenty's formulae\n",
    "def vincenty_distance(llh1, llh2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        llh1 : [latitude,longitude] (deg)\n",
    "        llh2 : [latitude,longitude] (deg)\n",
    "    Returns:\n",
    "        d : distance between llh1 and llh2 (m)\n",
    "    \"\"\"\n",
    "    d, az = np.array(pmv.vdist(llh1[:, 0], llh1[:, 1], llh2[:, 0], llh2[:, 1]))\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "# Compute score\n",
    "def calc_score(llh, llh_gt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        llh : [latitude,longitude] (deg)\n",
    "        llh_gt : [latitude,longitude] (deg)\n",
    "    Returns:\n",
    "        score : (m)\n",
    "    \"\"\"\n",
    "    d = vincenty_distance(llh, llh_gt)\n",
    "    score = np.mean([np.quantile(d, 0.50), np.quantile(d, 0.95)])\n",
    "\n",
    "    return score\n",
    "\n",
    "gnss_df = pd.read_csv(r'D:\\kaggle\\GSDC2022\\smartphone-decimeter-2022\\baseline_locations_train_CV.csv')  # GNSS data\n",
    "gt_df = pd.read_csv(r'D:\\kaggle\\GSDC2022\\smartphone-decimeter-2022\\ground_truths_train.csv')  # ground truth\n",
    "\n",
    "gnss_df = gnss_df.drop(columns=['tripId', 'UnixTimeMillis', 'LatitudeDegrees', 'LongitudeDegrees']).reset_index().drop(columns=['level_4', 'level_5'])\n",
    "gnss_df.columns = gt_df.columns\n",
    "gt_df = gt_df[gt_df['tripId'].isin(gnss_df['tripId'])].reset_index(drop=True)\n",
    "llh_gt = gt_df[['LatitudeDegrees', 'LongitudeDegrees']].to_numpy()\n",
    "plh_gt = gnss_df[['LatitudeDegrees', 'LongitudeDegrees']].to_numpy()\n",
    "score = calc_score(plh_gt, llh_gt)\n",
    "score\n",
    "\n",
    "#kinematic:3.656\n",
    "#single:9.4005\n",
    "#dgps：12707488.455379382\n",
    "\n",
    "#l1+l2+l5+l6：528.3245\n",
    "#l1+l2:512.05267\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting D:\\kaggle\\GSDC2022\\config\\bases.sta\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
